# 对attention的理解

## 点积缩放注意力

为什么score写成这样

score = Q.transpose()K/sqrt(d)

1. 高斯距离 中 q^2 会在softmax的时候成为指数，分子分母都有，约掉
2. ki^2 由于一般后面要过layernorm，会把数据分布拉回到均值为0，方差为1的状态，所以加不加常量已经无所谓了，去掉减少计算量
3. 为什么要除以 sqrt(d) ： ~~为了保证结果的数据分布方差没有改变~~ 为了均贫富，反向传播时每个参与计算softmax的参数都有比较客观的导数，但是又不会太大

## Bahdanau 的注意力机制的直觉感受

从正向的角度来看，每一个ctx，都考虑St‘关于所有Ht的注意力
St’对应目标端的一个token，Ht t从1～T一共有T个，对应源端T个token
注意力score的计算是三次矩阵乘法一次加法一次tanh激活
这样在计算图中就将原始的ht和ctx联系起来了，也就是说每一个ht的变化对结果的变化都有影响，都有导数
对比传统rnn，只有最后一个ht对结果有影响

假设正向传播出来的一个token和训练结果差异较大，那么交叉熵就比较大
反向传播给context，告诉它：你的注意力集中错了！
这时，就要调整score计算中的相关参数
怎么调整呢？
原先注意的token，我们不应该把注意力集中在这上面
也就是说，这个st‘和这个特定的ht，在通过score进行计算时，分数要减少
从偏导数的角度看，如果此时score中的三个矩阵固定，剩下可以变换的参数就是st’和ht
而st‘和ht是通过token的embedding向量变换而来的，那么直觉上可以理解为：
如果按照加法定义源空间和目标空间token的相似性，这时要让他们距离增大相似性减小
怎么调整呢，就是按照梯度的反方向

换一个角度来思考验证这种直觉，如果score函数使用点积缩放注意力呢？
点积代表着两个向量的相似性，这时点积越小越好，也就是在每一个维度，如果st’是正，那么ht就是负
总之就是保证相乘后结果为负数，在空间中的感觉就是处处相反，完全没有相似性。

所以可以感觉出来，attention机制在反向传播中调整的一个可以被直觉理解的角度是调整token在空间中的距离
这个距离可以理解成不同语言中两个词的意思相似程度。
通过attention，实际上模型学习到了词含义的相似性。

### lstm resnet attention are talking about the same theme

都是在把前面层次的参数尽量和输出纠缠起来，反向传播时loss可以尽可能影响到前面层次的参数